{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a8a33-9f85-4da2-94dc-68b6b2cf9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import *\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import string\n",
    "import gc\n",
    "import nltk\n",
    "nltk.download('stopwords')  \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "\n",
    "import contractions\n",
    "import emoji\n",
    "from html import unescape\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, RandomSampler, SequentialSampler, random_split\n",
    "# import torchtext\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import time\n",
    "import h5py\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b46be-812b-4753-8dfa-8ad8c534e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "random_state=42\n",
    "setup_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f085b6-9bc7-4644-b0ab-88dae95fba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'png'\")\n",
    "# La siguiente línea proporciona gráficos de mejor calidad en pantallas HiDPI\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865aeea-24a0-43fd-b96b-400f367b5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es para poder usar progress_apply\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed73a96-3e55-4bac-85cc-d6ece782a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_cell_magic('capture', '', '\\n!pip install ipython-autotime\\n \\n%load_ext autotime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821587c7-6b86-40e2-addf-30b3cbe58fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proporción de valores faltantes\n",
    "def missing_values(df):\n",
    "    df_nulls=pd.concat([df.dtypes, df.isna().sum(), df.isna().sum()/len(df)], axis=1)\n",
    "    df_nulls.columns = [\"type\",\"count\",\"missing_ratio\"]\n",
    "    df_nulls=df_nulls[df_nulls[\"count\"]>0]\n",
    "    df_nulls.sort_values(by=\"missing_ratio\", ascending=False)\n",
    "    return df_nulls\n",
    "\n",
    "#valores atípicos según la regla de 3 sigma\n",
    "def outlier(data):\n",
    "    data_mean, data_std = np.mean(data), np.std(data)\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in data if x < lower or x > upper]\n",
    "    outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "    return len(outliers)\n",
    "\n",
    "# estadísticas de descripción completa \n",
    "def describe_full(df, target_name=\"\"):\n",
    "    data_describe = df.describe().T\n",
    "    df_numeric = df._get_numeric_data()\n",
    "    if target_name in df.columns:\n",
    "        corr_with_target=df_numeric.drop(target_name, axis=1).apply(lambda x: x.corr(df_numeric[target_name]))\n",
    "        data_describe['corr_with_target']=corr_with_target\n",
    "    dtype_df = df_numeric.dtypes\n",
    "    data_describe['dtypes'] = dtype_df\n",
    "    data_null = df_numeric.isnull().sum()/len(df) * 100\n",
    "    data_describe['Missing %'] = data_null\n",
    "    Cardinality = df_numeric.apply(pd.Series.nunique)\n",
    "    data_describe['Cardinality'] = Cardinality\n",
    "    df_skew = df_numeric.skew(axis=0, skipna=True)\n",
    "    data_describe['Skew'] = df_skew\n",
    "    data_describe['outliers']=[outlier(df_numeric[col]) for col in df_numeric.columns]\n",
    "    data_describe['kurtosis']=df_numeric.kurtosis()\n",
    "    return data_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805557b-fdc6-4c3c-81aa-66462cf4bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_report(y_true, y_pred):\n",
    "    display(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T)\n",
    "    \n",
    "def plot_roc(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        if not ax: fig, ax = plt.subplots(1, 1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "        ax.plot([0, 1], [0, 1],'r--')\n",
    "        ax.plot(fpr, tpr, lw=2, label=label)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_title(\n",
    "             'ROC curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(fpr, tpr):.2}')\n",
    "        ax.set_xlabel('False Positive Rate (FPR)')\n",
    "        ax.set_ylabel('True Positive Rate (TPR)')\n",
    "        ax.annotate(f'AUC: {auc(fpr, tpr):.2}', xy=(.43, .025))\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax\n",
    "    \n",
    "\n",
    "def plot_pr(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "        if not ax: fig, ax = plt.subplots()\n",
    "        ax.plot([0, 1], [1, 0],'r--')    \n",
    "        ax.plot(recall, precision, lw=2, label=label)\n",
    "        ax.legend()\n",
    "        ax.set_title(\n",
    "            'Precision-recall curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(recall, precision):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_xlim(-0.05, 1.05)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f1c80-f7ff-447e-92aa-b0603f4b3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_h5(in_object, outfile):\n",
    "  with h5py.File('data.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('dataset_1', data=in_object)\n",
    "\n",
    "def from_h5(in_file):\n",
    "  with h5py.File('data.h5','r') as h5f:\n",
    "     return h5f['dataset_1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea15fd6-e784-4855-b1fb-5b11ae312243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('/datasets/imdb_reviews.tsv', sep='\\t', dtype={'votes': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370f6f0-7121-48f9-8e83-7b0e483bc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.head()\n",
    "df_reviews.info()\n",
    "df_reviews[df_reviews[\"average_rating\"].isna()]\n",
    "\n",
    "# Se han perdido algunos registros, es insignificante, los eliminamos\n",
    "df_reviews = df_reviews[~df_reviews[\"average_rating\"].isna()]\n",
    "\n",
    "sns.countplot(df_reviews[\"pos\"])\n",
    "# Como vemos, en nuestro caso el conjunto de datos está bastante equilibrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba49045-8eb2-44d0-98a3-ad85f844b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_full(df_reviews)\n",
    "\n",
    "# # EDA\n",
    "#Revisemos el número de películas y reseñas a lo largo de los años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81e6ba-d079-41da-81aa-d041a48feff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "ax = axs[0]\n",
    "\n",
    "dft1 = df_reviews[['tconst', 'start_year']].drop_duplicates()     ['start_year'].value_counts().sort_index()\n",
    "dft1 = dft1.reindex(index=np.arange(dft1.index.min(), max(dft1.index.max(), 2021))).fillna(0)\n",
    "dft1.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Number of Movies Over Years')\n",
    "\n",
    "ax = axs[1]\n",
    "\n",
    "dft2 = df_reviews.groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "\n",
    "dft2.plot(kind='bar', stacked=True, label='#reviews (neg, pos)', ax=ax)\n",
    "\n",
    "dft2 = df_reviews['start_year'].value_counts().sort_index()\n",
    "dft2 = dft2.reindex(index=np.arange(dft2.index.min(), max(dft2.index.max(), 2021))).fillna(0)\n",
    "dft3 = (dft2/dft1).fillna(0)\n",
    "axt = ax.twinx()\n",
    "dft3.reset_index(drop=True).rolling(5).mean().plot(color='orange', label='reviews per movie (avg over 5 years)', ax=axt)\n",
    "\n",
    "lines, labels = axt.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='upper left')\n",
    "\n",
    "ax.set_title('Number of Reviews Over Years')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "# Verifiquemos la distribución del número de reseñas por película con el recuento exacto y KDE (solo para aprender cómo puede diferir del recuento exacto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e217082-d18c-4a1a-a016-2dd910531492",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.groupby('tconst')['review'].count()     .value_counts()     .sort_index()\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_title('Bar Plot of #Reviews Per Movie')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.groupby('tconst')['review'].count()\n",
    "sns.kdeplot(dft, ax=ax)\n",
    "ax.set_title('KDE Plot of #Reviews Per Movie')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e5f39-b071-45cb-8bfb-579037997b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ffa8e-c718-41a2-a553-dbcff0cbac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "dft = df_reviews.query('ds_part == \"train\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('The train set: distribution of ratings')\n",
    "\n",
    "ax = axs[1]\n",
    "dft = df_reviews.query('ds_part == \"test\"')['rating'].value_counts().sort_index()\n",
    "dft = dft.reindex(index=np.arange(min(dft.index.min(), 1), max(dft.index.max(), 11))).fillna(0)\n",
    "dft.plot.bar(ax=ax)\n",
    "ax.set_ylim([0, 5000])\n",
    "ax.set_title('The test set: distribution of ratings')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02233fab-63e5-4973-9d02-dd2f484c105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de reseñas negativas y positivas a lo largo de los años para dos partes del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72599dac-d390-40d9-a983-5d062256c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(16, 8), gridspec_kw=dict(width_ratios=(2, 1), height_ratios=(1, 1)))\n",
    "\n",
    "ax = axs[0][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('The train set: number of reviews of different polarities per year')\n",
    "\n",
    "ax = axs[0][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"train\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('The train set: distribution of different polarities per movie')\n",
    "\n",
    "ax = axs[1][0]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['start_year', 'pos'])['pos'].count().unstack()\n",
    "dft.index = dft.index.astype('int')\n",
    "dft = dft.reindex(index=np.arange(dft.index.min(), max(dft.index.max(), 2020))).fillna(0)\n",
    "dft.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('The test set: number of reviews of different polarities per year')\n",
    "\n",
    "ax = axs[1][1]\n",
    "\n",
    "dft = df_reviews.query('ds_part == \"test\"').groupby(['tconst', 'pos'])['pos'].count().unstack()\n",
    "sns.kdeplot(dft[0], color='blue', label='negative', kernel='epa', ax=ax)\n",
    "sns.kdeplot(dft[1], color='green', label='positive', kernel='epa', ax=ax)\n",
    "ax.legend()\n",
    "ax.set_title('The test set: distribution of different polarities per movie')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2df0a2-bdaa-4d1f-8799-867e443451df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Procedimiento de evaluación\n",
    "\n",
    "# Creación de una rutina de evaluación que pueda utilizarse para todos los modelos de este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e1ec3-9d10-4f2e-bd56-7347d9a8d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_features, train_target, test_features, test_target):\n",
    "    \n",
    "    eval_stats = {}\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 6)) \n",
    "    \n",
    "    for type, features, target in (('train', train_features, train_target), ('test', test_features, test_target)):\n",
    "        \n",
    "        eval_stats[type] = {}\n",
    "    \n",
    "        pred_target = model.predict(features)\n",
    "        pred_proba = model.predict_proba(features)[:, 1]\n",
    "        \n",
    "        # F1\n",
    "        f1_thresholds = np.arange(0, 1.01, 0.05)\n",
    "        f1_scores = [metrics.f1_score(target, pred_proba>=threshold) for threshold in f1_thresholds]\n",
    "        \n",
    "        # ROC\n",
    "        fpr, tpr, roc_thresholds = metrics.roc_curve(target, pred_proba)\n",
    "        roc_auc = metrics.roc_auc_score(target, pred_proba)    \n",
    "        eval_stats[type]['ROC AUC'] = roc_auc\n",
    "\n",
    "        # PRC\n",
    "        precision, recall, pr_thresholds = metrics.precision_recall_curve(target, pred_proba)\n",
    "        aps = metrics.average_precision_score(target, pred_proba)\n",
    "        eval_stats[type]['APS'] = aps\n",
    "        \n",
    "        if type == 'train':\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'green'\n",
    "\n",
    "        # F1 Score\n",
    "        ax = axs[0]\n",
    "        max_f1_score_idx = np.argmax(f1_scores)\n",
    "        ax.plot(f1_thresholds, f1_scores, color=color, label=f'{type}, max={f1_scores[max_f1_score_idx]:.2f} @ {f1_thresholds[max_f1_score_idx]:.2f}')\n",
    "        # estableciendo cruces para algunos umbrales\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(f1_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(f1_thresholds[closest_value_idx], f1_scores[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('threshold')\n",
    "        ax.set_ylabel('F1')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'F1 Score') \n",
    "\n",
    "        # ROC\n",
    "        ax = axs[1]    \n",
    "        ax.plot(fpr, tpr, color=color, label=f'{type}, ROC AUC={roc_auc:.2f}')\n",
    "        # estableciendo cruces para algunos umbrales\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(roc_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'            \n",
    "            ax.plot(fpr[closest_value_idx], tpr[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.legend(loc='lower center')        \n",
    "        ax.set_title(f'ROC Curve')\n",
    "        \n",
    "        # PRC\n",
    "        ax = axs[2]\n",
    "        ax.plot(recall, precision, color=color, label=f'{type}, AP={aps:.2f}')\n",
    "        # estableciendo cruces para algunos umbrales\n",
    "        for threshold in (0.2, 0.4, 0.5, 0.6, 0.8):\n",
    "            closest_value_idx = np.argmin(np.abs(pr_thresholds-threshold))\n",
    "            marker_color = 'orange' if threshold != 0.5 else 'red'\n",
    "            ax.plot(recall[closest_value_idx], precision[closest_value_idx], color=marker_color, marker='X', markersize=7)\n",
    "        ax.set_xlim([-0.02, 1.02])    \n",
    "        ax.set_ylim([-0.02, 1.02])\n",
    "        ax.set_xlabel('recall')\n",
    "        ax.set_ylabel('precision')\n",
    "        ax.legend(loc='lower center')\n",
    "        ax.set_title(f'PRC')        \n",
    "\n",
    "        eval_stats[type]['Accuracy'] = metrics.accuracy_score(target, pred_target)\n",
    "        eval_stats[type]['F1'] = metrics.f1_score(target, pred_target)\n",
    "    \n",
    "    df_eval_stats = pd.DataFrame(eval_stats)\n",
    "    df_eval_stats = df_eval_stats.round(2)\n",
    "    df_eval_stats = df_eval_stats.reindex(index=('Accuracy', 'F1', 'APS', 'ROC AUC'))\n",
    "    \n",
    "    print(df_eval_stats)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9436755-c526-447c-ba97-2792b0950300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalización\n",
    "\n",
    "# Suponemos que todos los modelos a continuación aceptan textos en minúsculas y sin dígitos, signos de puntuación, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34937203-0162-424e-abf0-50fefb0f39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "  return \" \".join(t for t in sentence.split() if not t.isdigit() and t.isalpha())\n",
    "\n",
    "\n",
    "def clean_column(in_data:pd.Series) -> np.ndarray:\n",
    "  df = in_data.str.strip().str.lower().str.strip(string.punctuation+\" \")\n",
    "  df = df.str.replace(\"[^a-zA-Z]\", \" \")\n",
    "  df = np.vectorize(contractions.fix)(df)\n",
    "  df = np.vectorize(emoji.demojize)(df)\n",
    "  df = np.vectorize(unescape)(df)\n",
    "  df = np.vectorize(clean_text)(df)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d57759-959f-49b0-8c3f-b5ffbed9ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('/content/drive/My Drive/imdb.csv.zip'):\n",
    "  df_reviews = pd.read_csv('/content/drive/My Drive/imdb.csv.zip')\n",
    "else:\n",
    "  df_reviews['review_norm'] = clean_column(df_reviews['review'])\n",
    "  df_reviews.to_csv(\"imdb.csv\", index=False)\n",
    "  try:\n",
    "    get_ipython().system('zip imdb.csv.zip imdb.csv')\n",
    "    get_ipython().system('cp imdb.csv.zip /content/drive/My\\\\ Drive/')\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "df_reviews['review_norm'].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d347e1-31b7-4f50-8952-8abfa2629079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de entrenamiento/prueba\n",
    "#Por suerte, el conjunto de datos ya está dividido en partes de entrenamiento/prueba. La bandera correspondiente es 'ds_part'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855635b-a759-46df-8e2a-9353170eb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_train = df_reviews.query('ds_part == \"train\"').copy()\n",
    "df_reviews_test = df_reviews.query('ds_part == \"test\"').copy()\n",
    "\n",
    "train_target = df_reviews_train['pos']\n",
    "test_target = df_reviews_test['pos']\n",
    "\n",
    "print(df_reviews_train.shape)\n",
    "print(df_reviews_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1c1b9-2a26-41c1-afe6-b773e0df1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"pos\"\n",
    "features = list(set(df_reviews_train.columns)-set([target])-set([\"review\"]))\n",
    "\n",
    "X_train, X_test, y_train, y_test =  df_reviews_train[features], df_reviews_test[features], train_target, test_target\n",
    "\n",
    "# >También en casos reales es necesario dividir X_train para entrenar/validar conjuntos\n",
    "# # Modelo 0 - Constante\n",
    "\n",
    "model = DummyClassifier().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "display_classification_report(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax = ax.flatten()\n",
    "_ = plot_pr(y_test, y_pred, ax=ax[0],label=\"DummyClassifier\")\n",
    "_ = plot_roc(y_test, y_pred, ax=ax[1],label=\"DummyClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576e111-9ad2-4ef3-951c-a05701cff17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyClassifier().fit(X_train, y_train)\n",
    "evaluate_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317ba45-1b09-449b-a488-0590b5e44913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo una suposición aleatoria 50/50\n",
    "# # Modelo 1 BoW + Naive Bayes\n",
    "# Probemos el enfoque clásico: CountVectorizer(BoW) + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624e012-43eb-4438-b72b-3f8866aa902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(df_reviews_train['review_norm'].values)\n",
    "classifier = MultinomialNB()\n",
    "targets = df_reviews_train['pos'].values\n",
    "classifier = classifier.fit(counts, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0b899-9ffa-4f81-b40d-b09bef26dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(vectorizer.transform(df_reviews_test['review_norm'].values))\n",
    "display_classification_report(y_test, y_pred)\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax = ax.flatten()\n",
    "_ = plot_pr(y_test, y_pred, ax=ax[0],label=\"Naive Bayes\")\n",
    "_ = plot_roc(y_test, y_pred, ax=ax[1],label=\"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ce4ab-1b8b-4f4c-a6ff-12ca40089b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(classifier, counts, targets, vectorizer.transform(df_reviews_test['review_norm'].values), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc30e59-e751-487a-a6f0-594a73c2dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como vemos, por alguna razón el Naive Bayes clásico fue popular, sin ningún problema obtuvimos un resultado bastante bueno, que está sobreajustado pero no es un problema para ese caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d5cf6-bf5d-4662-a7a1-81a76e84e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "del classifier, counts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359f358-c908-4590-8e80-454b9b5d3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelo 2 - NLTK, TF-IDF y LR\n",
    "\n",
    "# ### TF-IDF\n",
    "\n",
    "# En lugar de conteos, intentemos usar un TF-IDF más sofisticado y la red neuronal más simple ;) -> Regresión logística. Para simplificar, no usaré validación cruzada como en el modelo anterior.\n",
    "\n",
    "# También uso ngram (para evitar errores tipográficos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4fd5d-7672-4728-8925-d59df0118c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv=TfidfVectorizer(min_df=0, max_features=10_000, strip_accents='unicode',lowercase =True,\n",
    "                            analyzer='word', token_pattern=r'\\w{3,}', ngram_range=(1,1),\n",
    "                            use_idf=True,smooth_idf=True, sublinear_tf=True, stop_words = \"english\")   \n",
    "X_train_tfv = tfv.fit_transform(df_reviews_train['review_norm'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45412eb2-baeb-43c1-83dc-9b16ba9d7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(X_train_tfv, y_train)\n",
    "y_pred = lr.predict(tfv.transform(df_reviews_test['review_norm'].values))\n",
    "display_classification_report(y_test, y_pred)\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax = ax.flatten()\n",
    "_ = plot_pr(y_test, y_pred, ax=ax[0],label=\"LR+Tf-Idf\")\n",
    "_ = plot_roc(y_test, y_pred, ax=ax[1],label=\"LR+Tf-Idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc91563-6bb4-4881-bc70-360bdf3c4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lr, X_train_tfv, y_train, tfv.transform(df_reviews_test['review_norm'].values), y_test)\n",
    "\n",
    "# Creo que obtuvimos un mejor resultado en este caso, parece que las cifras están cerca de CountVectoriser y del modelo Naive Bayes, pero es un resultado\n",
    "#mejor considerado, que no está tan sobreajustado como el anterior, por lo tanto, los números son más confidenciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c06ca-30bd-4c27-b7ab-9ec240bf8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=random_state, shuffle=True)\n",
    "f1_cv = cross_val_score(lr, X_train_tfv, y_train, cv=kf, scoring='f1')\n",
    "f1_cv.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd19205-c3d9-41e1-b0a6-5395fa9d3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66d8d6-eabb-44a3-9db3-c3369882b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.Series([\n",
    "      'I did not simply like it, not my kind of movie.',\n",
    "      'Well, I was bored and felt asleep in the middle of the movie.',\n",
    "      'I was really fascinated with the movie',    \n",
    "      'Even the actors looked really old and disinterested, and they got paid to be in the movie. What a soulless cash grab.',\n",
    "      'I didn\\'t expect the reboot to be so good! Writers really cared about the source material',\n",
    "      'The movie had its upsides and downsides, but I feel like overall it\\'s a decent flick. I could see myself going to see it again.',\n",
    "      'What a rotten attempt at a comedy. Not a single joke lands, everyone acts annoying and loud, even kids won\\'t like this!',\n",
    "      'Launching on Netflix was a brave move & I really appreciate being able to binge on episode after episode, of this exciting intelligent new drama.'])\n",
    "\n",
    "def show_test_proba(model, data):\n",
    "    my_reviews_pred_prob = model.predict_proba(data)[:, 1]\n",
    "    for i, review in enumerate(texts.str.slice(0, 100)):\n",
    "      print(f'{my_reviews_pred_prob[i]:.2f}:  {review}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84875744-dd56-4f80-a276-f7aa9ff2f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test_proba(lr, data=tfv.transform(clean_column(texts)).todense())\n",
    "\n",
    "# # Model 3 - spaCy, TF-IDF y LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71c9b3-1709-4329-9a11-ee77b54b5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system(\"nvidia-smi | grep 'CUDA Version'\")\n",
    "\n",
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff684d0d-30d7-43ab-8327-b81ef0de9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789afb1-c360-4085-9b56-855b4231c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec543c6-2577-49e1-ab66-d6640062ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_preprocessing_3(X):\n",
    "  nlp_pipes = nlp.pipe(X, disable=[\"parser\", \"ner\"], n_threads=4, batch_size=1000) \n",
    "  return np.array([' '.join(token.lemma_ for token in doc) for doc in nlp_pipes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb07f9f-9252-46b5-86e3-2cdac9112f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_3(text):\n",
    "    return ' '.join(token.lemma_ for token in nlp(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd1196-421a-41f4-8c52-6a97f4f2ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfv = array_preprocessing_3(df_reviews_train[\"review\"].values)\n",
    "tfv=TfidfVectorizer(min_df=0, max_features=10_000, strip_accents='unicode',lowercase =True,\n",
    "                            analyzer='word', token_pattern=r'\\w{3,}', ngram_range=(1,1),\n",
    "                            use_idf=True,smooth_idf=True, sublinear_tf=True, stop_words = \"english\")   \n",
    "X_train_tfv = tfv.fit_transform(X_train_tfv)\n",
    "\n",
    "X_test_tfv = array_preprocessing_3(df_reviews_test[\"review\"].values)\n",
    "X_test_tfv = tfv.transform(X_test_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58063f6-7e23-4749-99d1-4636854b0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(X_train_tfv, y_train)\n",
    "y_pred = lr.predict(X_test_tfv)\n",
    "display_classification_report(y_test, y_pred)\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax = ax.flatten()\n",
    "_ = plot_pr(y_test, y_pred, ax=ax[0],label=\"LR+Tf-Idf+lemmas\")\n",
    "_ = plot_roc(y_test, y_pred, ax=ax[1],label=\"LR+Tf-Idf+lemmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414687c6-08b5-4efb-86f5-f9187fb0638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lr, X_train_tfv, y_train, X_test_tfv, y_test)\n",
    "\n",
    "# ### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8bfef5-f116-4b60-8b1c-822fff0263c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test_proba(lr, data=tfv.transform(np.vectorize(text_preprocessing_3)(pd.Series(clean_column(texts)))).todense())\n",
    "\n",
    "\n",
    "# # Model 4 - spaCy, TF-IDF y LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b834b2e-5fec-4c97-969d-05ecbc08b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier().fit(X_train_tfv, y_train)\n",
    "y_pred = model.predict(X_test_tfv)\n",
    "display_classification_report(y_test, y_pred)\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax = ax.flatten()\n",
    "_ = plot_pr(y_test, y_pred, ax=ax[0],label=\"LGBMClassifier+Tf-Idf+lemmas\")\n",
    "_ = plot_roc(y_test, y_pred, ax=ax[1],label=\"LGBMClassifier+Tf-Idf+lemmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04e886-2745-4e10-9501-54425c5294c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_train_tfv, y_train, X_test_tfv, y_test)\n",
    "\n",
    "# ### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e2a51-2fbc-4f5b-a3aa-14e59c8431ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_test_proba(model, data=tfv.transform(np.vectorize(text_preprocessing_3)(pd.Series(clean_column(texts)))).todense())\n",
    "\n",
    "# # Model 5 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6986d-dcd5-4ef5-902e-d21ae0de411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_model = RandomForestClassifier(n_estimators=10, max_depth=10).fit(X_train_tfv, y_train)\n",
    "evaluate_model(skl_model, X_train_tfv, y_train, X_test_tfv, y_test)\n",
    "\n",
    "# Por defecto, el bosque aleatorio muestra malos resultados, la clave es el hiperajuste, el CV, etc. (lo cual consume mucho tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e9c80-3bcc-41bf-8f4e-af65976fa8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = skl_model.predict(X_test_tfv)\n",
    "display_classification_report(y_test, y_pred)\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax = ax.flatten()\n",
    "_ = plot_pr(y_test, y_pred, ax=ax[0],label=\"Naive Bayes\")\n",
    "_ = plot_roc(y_test, y_pred, ax=ax[1],label=\"Naive Bayes\")\n",
    "\n",
    "# #  Model 9 - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af502dae-4b54-4a90-bb20-d3494d60a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertConfig\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# En primer lugar, verifiquemos la longitud máxima posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c2188-0803-47c0-ab7b-498f90ca7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_tokens(s):\n",
    "  return len(s.split())\n",
    "\n",
    "df = df_reviews_train.copy()\n",
    "df[\"len\"] = np.vectorize(len_tokens)(df[\"review_norm\"])\n",
    "print(\"max len is: {}\".format(max(list(map(len, tokenizer.batch_encode_plus(df.sort_values(by=\"len\", ascending=False)[:1][\"review_norm\"].to_list())[\"input_ids\"])))))\n",
    "sns.displot(df[\"len\"])\n",
    "del df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c9f55-f1c9-4592-a7c4-a0e5137a4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En un caso real podríamos crear incrustaciones por fragmento 512 y agruparlos (es decir, o de alguna otra manera) pero en este caso vemos que, \n",
    "#de acuerdo con la longitud, las oraciones que son mayores a 512, en realidad no son tan importantes. pero pensemos que max_length=128 en nuestro\n",
    "#caso para un cálculo rápido (bert tiene una complejidad O(n^2) que depende de la longitud de la entrada)\n",
    "\n",
    "max_length = 128\n",
    "default_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cpu_device = torch.device('cpu')\n",
    "bert_path=\"bert-base-uncased\"\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e6957-f2e3-49b2-bd48-c1d1a2bf87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizersDataset(Dataset):\n",
    "\n",
    "    def __init__(self, in_data, targets, tokenizer, max_len, splitter_func=None):\n",
    "        self.data = in_data\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.splitter_func = splitter_func\n",
    "        assert len(in_data)==len(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = [self.data[idx]]\n",
    "        is_pretokenized = self.splitter_func is not None\n",
    "        if is_pretokenized:\n",
    "            batch = [self.splitter_func(sentence) for sentence in batch]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            batch,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            is_pretokenized=is_pretokenized,\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'token_type_ids': encoding['token_type_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'target' : self.targets[idx]\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def from_data(data, targets, tokenizer, max_len, batch_size=8):\n",
    "        ds = TokenizersDataset(\n",
    "            in_data=data,\n",
    "            targets=targets,\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=max_len,\n",
    "        )\n",
    "        return DataLoader(\n",
    "            ds,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            # num_workers=2, -> En Colab solo tengo una GPU\n",
    "            # pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d561584-8629-434d-a55b-12de53cbbb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = TokenizersDataset.from_data(df_reviews_train[\"review_norm\"].values, df_reviews_train[\"pos\"].values, tokenizer, max_len=max_length, batch_size=batch_size)\n",
    "test_dataloader = TokenizersDataset.from_data(df_reviews_test[\"review_norm\"].values, df_reviews_test[\"pos\"].values, tokenizer, max_len=max_length, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bf637-9c31-482a-8cd9-fc23579dd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4e78a-6024-415d-9e43-361b8ef22165",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples=2\n",
    "model = SentimentClassifier(n_examples)\n",
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab381d-038c-4765-8873-8e25b11ef81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "    return torch.mean(torch.eq(predicted, labels).float()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ffed8b-96bd-4490-9c7e-3c8df6f3d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples, epoch):\n",
    "      pbar = tqdm(data_loader, desc=f\"Epoch {epoch + 1}. Train Loss: {0}\")\n",
    "      device = default_device\n",
    "      model.to(device)\n",
    "      model = model.train()\n",
    "      loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "      losses = []\n",
    "      correct_predictions = 0\n",
    "      for step, d in enumerate(pbar):\n",
    "          targets = d[\"target\"].to(device)\n",
    "          outputs = model(\n",
    "            input_ids=d[\"input_ids\"].to(device),\n",
    "            attention_mask=d[\"attention_mask\"].to(device)\n",
    "          ).to(device)\n",
    "          _, preds = torch.max(outputs, dim=1)\n",
    "          loss = loss_fn(outputs, targets)\n",
    "          correct_predictions += torch.sum(preds == targets)\n",
    "          losses.append(loss.item())\n",
    "          loss.backward()\n",
    "          nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "          optimizer.step()\n",
    "          scheduler.step()\n",
    "          optimizer.zero_grad()\n",
    "          \n",
    "          acc = accuracy(outputs, targets)\n",
    "          pbar.set_description(f\"Epoch:{epoch + 1}.Train Loss:{loss:.4} Acc:{acc:.4}\")\n",
    "          if step%100==0:gc.collect();torch.cuda.empty_cache();\n",
    "          \n",
    "          \n",
    "      return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740aea5d-0f7f-49a3-8fdc-fd93c747dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(model,train_dataloader,loss_fn,optimizer,default_device,scheduler,len(df_reviews_train), epoch)\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c786bc0-9eda-4c96-97f4-999b56230589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONCLUSIONES\n",
    "\n",
    "#Se probaron varios modelos con diferentes métodos: modelos lineales, mediante lematización, una bolsa de palabras, TF-IDF y transformadores, BERT.\n",
    "#Según la puntuación F1, los modelos BoW con Naive Bayes resultaron más rápidos y eficaces (creo que también podríamos usar, en lugar de este modelo, el modelo xgboost, por ejemplo).\n",
    "#Algunos modelos inteligentes con el enfoque BERT no mostraron resultados significativos, pero debido a la limitación de recursos, no se probó un buen modelo (era el único modelo simple) sin buscar hiperparámetros ni otras optimizaciones.\n",
    "# \n",
    "\n",
    "# BoW + Naive Bayes\n",
    "# \n",
    "# <div class=\"stream\"><div class=\"output_subarea output_text\"><pre>          train  test\n",
    "# Accuracy   0.90  0.81\n",
    "# F1         0.89  0.80\n",
    "# APS        0.96  0.87\n",
    "# ROC AUC    0.96  0.89\n",
    "# </pre></div></div>\n",
    "# \n",
    "# \n",
    "# NLTK, TF-IDF y LR\n",
    "# \n",
    "# \n",
    "# <pre>          train  test\n",
    "# Accuracy   0.93  0.88\n",
    "# F1         0.93  0.88\n",
    "# APS        0.98  0.95\n",
    "# ROC AUC    0.98  0.95\n",
    "# </pre>\n",
    "# \n",
    "# \n",
    "# spaCy, TF-IDF and LR\n",
    "# \n",
    "# \n",
    "# <div class=\"stream\"><div class=\"output_subarea output_text\"><pre>          train  test\n",
    "# Accuracy   0.92  0.88\n",
    "# F1         0.92  0.88\n",
    "# APS        0.98  0.95\n",
    "# ROC AUC    0.98  0.95\n",
    "# </pre></div></div>\n",
    "# \n",
    "# \n",
    "# spaCy, TF-IDF and LGBMClassifier\n",
    "# \n",
    "# \n",
    "# <pre>          train  test\n",
    "# Accuracy   0.91  0.85\n",
    "# F1         0.91  0.86\n",
    "# APS        0.97  0.93\n",
    "# ROC AUC    0.97  0.93\n",
    "# </pre>\n",
    "\n",
    "#Como observamos, el mejor resultado por prueba y puntuación f1 se obtuvo usando TfIdf+LR, lo cual tiene sentido en este caso, el análisis desentimiento.\n",
    "\n",
    "#También se ajustó el modelo BERT, pero debido a la limitación de recursos, no se entrenó ni evaluó correctamente el modelo y, por lo tanto,\n",
    "#no se consideró en la etapa de resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
